{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ruamel.yaml\n",
    "#!pip install --upgrade jinja2\n",
    "#!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('allos_cluster_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 13', 'Unnamed: 14','Unnamed: 15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sweetviz as sv\n",
    "# report = sv.analyze(df)\n",
    "# report.show_html('output.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dtale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dtale\n",
    "\n",
    "# # Assuming df is your DataFrame\n",
    "# # df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# d = dtale.show(df)\n",
    "# d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearMonth'] = df['Date'].dt.to_period('M')  # Cria uma nova coluna com o ano e o mês\n",
    "\n",
    "# Agrupa por 'Host name' e 'YearMonth' e conta os meses únicos para cada 'Host name'\n",
    "months_count = df.groupby('Host name')['YearMonth'].nunique()\n",
    "\n",
    "#print(months_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearMonth'] = df['Date'].dt.to_period('M')  # Cria uma nova coluna com o ano e o mês\n",
    "\n",
    "# Cria a tabela cruzada\n",
    "cross_tab = pd.crosstab(df['Host name'], df['YearMonth'])\n",
    "\n",
    "#print(cross_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month_sin'] = np.sin((df['Date'].dt.month-1)*(2.*np.pi/12))\n",
    "df['Month_cos'] = np.cos((df['Date'].dt.month-1)*(2.*np.pi/12))\n",
    "df['Day_sin'] = np.sin((df['Date'].dt.day-1)*(2.*np.pi/30.))\n",
    "df['Day_cos'] = np.cos((df['Date'].dt.day-1)*(2.*np.pi/30.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_date = pd.Timestamp('2000-01-01')\n",
    "df['TimeDifference'] = (df['Date'] - reference_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_encoded = df[['Host name', 'Branding interest', 'User gender',\n",
    "#        'City', 'Event name', 'Device category', 'Active users',\n",
    "#        'Engaged sessions', 'Sessions', 'New users', 'Event count', 'Month_sin', 'Month_cos',\n",
    "#        'Day_sin', 'Day_cos']]\n",
    "\n",
    "# df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_to_remove = ['compras.cariocashopping.com.br', 'compras.shoppingleblon.com.br', 'boulevardcampos.com.br']\n",
    "df = df[~df['Host name'].isin(hosts_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host name'] = df['Host name'].replace('www.montesclarosshopping.com.br', 'montesclarosshopping.com.br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host name'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Host name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of columns of type 'object'\n",
    "object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a temporary 'combined' column that combines the object columns without filling in the missing values\n",
    "df['combined_temp'] = df[object_columns].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "# Determine the maximum length of the underscore-separated values in the temporary 'combined' column\n",
    "max_len = df['combined_temp'].str.split('_').apply(len).max()\n",
    "\n",
    "# Define a function that joins a row into a string with exactly max_len underscore-separated values\n",
    "def join_row(row):\n",
    "    # Convert the row to a list\n",
    "    values = list(row.values.astype(str))\n",
    "    # If there are fewer than max_len values, append placeholders ('NA') to the list\n",
    "    while len(values) < max_len:\n",
    "        values.append('NA')\n",
    "    # If there are more than max_len values, remove the extra values\n",
    "    values = values[:max_len]\n",
    "    # Join the values into a string with underscore separators\n",
    "    return '_'.join(values)\n",
    "\n",
    "# Create the 'combined' column with the missing values filled in\n",
    "df['combined'] = df[object_columns].apply(join_row, axis=1)\n",
    "\n",
    "# Drop the temporary 'combined' column\n",
    "df.drop(columns=['combined_temp'], inplace=True)\n",
    "\n",
    "# Create a pivot table with the new column as the index\n",
    "pivot_table = df.pivot_table(index='combined')\n",
    "\n",
    "pivot_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table['Year'] = pivot_table['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "\n",
    "# Fit on the dataset and transform it\n",
    "df_imputed = imputer.fit_transform(pivot_table)\n",
    "\n",
    "# Convert the result back to a DataFrame\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=pivot_table.columns, index=pivot_table.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# Convert the numpy array back to a DataFrame\n",
    "df_imputed = pd.DataFrame(df_imputed)\n",
    "\n",
    "# Replace 0s with NaNs\n",
    "df_imputed.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# Store column and index information\n",
    "columns = df_imputed.columns\n",
    "index = df_imputed.index\n",
    "\n",
    "# Create an instance of SimpleImputer with strategy as 'mean'\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit on the dataset and transform it\n",
    "df_imputed = imputer.fit_transform(df_imputed)\n",
    "\n",
    "# Convert the result back to a DataFrame using the stored column and index information\n",
    "df_imputed = pd.DataFrame(df_imputed, columns=columns, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pivot_table.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_imputed.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = df_imputed['Active users'].isnull().sum()\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['Active users'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_imputed['Active users'].max())\n",
    "print(df_imputed['Active users'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['Active users'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['Active users'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['Active users'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df_imputed.reset_index(inplace=True)\n",
    "\n",
    "# Print the columns of the DataFrame\n",
    "print(df_imputed.columns)\n",
    "\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'combined' column into multiple columns\n",
    "df_split = df_imputed['combined'].str.split('_', n=len(object_columns)-1, expand=True)\n",
    "\n",
    "# Rename the new columns to match the original object columns\n",
    "df_split.columns = object_columns\n",
    "\n",
    "# Drop the 'combined' column from the original DataFrame\n",
    "df_imputed.drop(columns=['combined'], inplace=True)\n",
    "\n",
    "# Concatenate the original DataFrame with the new DataFrame\n",
    "df = pd.concat([df_imputed, df_split], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Month'] = df['Month'].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Month'] = df['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'year' and 'Month' to string\n",
    "df['Year'] = df['Year'].astype(str)\n",
    "df['Month'] = df['Month'].astype(str)\n",
    "\n",
    "# Combine 'year' and 'Month' columns\n",
    "df['year_month'] = df['Year'] + '_' + df['Month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_month'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_month'] = df['year_month'].str.replace('.0_', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year_month'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a tabela cruzada\n",
    "cross_tab_encod = pd.crosstab(df['Host name'], df['year_month'])\n",
    "#cross_tab_encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = df.pivot_table(index='Host name', columns='year_month', values='Active users', aggfunc='count')\n",
    "#pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por 'Host name' e 'YearMonth' e conta os meses únicos para cada 'Host name'\n",
    "months_count = df.groupby('Host name')['year_month'].nunique()\n",
    "\n",
    "print(months_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(['year_month', 'TimeDifference', 'Day', 'DayOfWeek', 'Month', 'Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Este código primeiro cria uma cópia do df1 chamada df1_1 e aplica o LabelEncoder a cada coluna de objeto. \n",
    "Em seguida, ele cria outra cópia do df1 chamada df2 e aplica o OneHotEncoder a cada coluna de objeto. \n",
    "O argumento drop='first' no OneHotEncoder evita a multicolinearidade removendo a primeira coluna dummy \n",
    "para cada variável categórica.\n",
    "\n",
    "'''\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "#  uma cópia do df1 \n",
    "df1_1 = df1.copy()\n",
    "\n",
    "#  um LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Aplique o LabelEncoder a cada coluna de objeto\n",
    "for col in df1_1.select_dtypes(include=['object']).columns:\n",
    "    df1_1[col] = le.fit_transform(df1_1[col])\n",
    "\n",
    "#  uma cópia do df1 para o OneHotEncoder\n",
    "df_2 = df1.copy()\n",
    "\n",
    "# Aplique o OneHotEncoder a cada coluna de objeto\n",
    "df_2 = pd.get_dummies(df_2, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1_1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupe por 'Host name' e calcule a média de cada grupo\n",
    "df_grouped_1 = df1_1.groupby('Host name').mean()\n",
    "\n",
    "# Reset the index\n",
    "df_grouped_1 = df_grouped_1.reset_index()\n",
    "\n",
    "df_grouped_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "\n",
    "# Selecione apenas as colunas numéricas e preencha os valores NA\n",
    "df_numeric = df_grouped_1.select_dtypes(include=[np.number])\n",
    "df_numeric = df_numeric.fillna(df_numeric.mean())\n",
    "\n",
    "# Aplique PCA\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_numeric)\n",
    "\n",
    "# Aplique KMeans ao resultado do PCA\n",
    "# O número de clusters é 3\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_pca)\n",
    "\n",
    "# Adicione os rótulos de cluster ao DataFrame\n",
    "df_grouped_1['cluster'] = kmeans.labels_\n",
    "\n",
    "# Calcule o Silhouette Score\n",
    "score = silhouette_score(df_pca, kmeans.labels_)\n",
    "print(\"Silhouette Score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Crie um DataFrame com os resultados do PCA e os rótulos de cluster\n",
    "df_plot = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n",
    "df_plot['cluster'] = kmeans.labels_\n",
    "df_plot['Host name'] = df_grouped_1['Host name']\n",
    "\n",
    "# Crie um gráfico de dispersão dos resultados do PCA, colorido pelos rótulos de cluster\n",
    "fig = px.scatter(df_plot, x='PC1', y='PC2', color='cluster', hover_data=['Host name'])\n",
    "\n",
    "# Mostre o gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_1[['Host name', 'cluster']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_1[['Host name', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_1_ = df_grouped_1[['Host name', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_1_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mescla df1_1 e df_grouped_1_ com base na coluna 'Host name'\n",
    "merged_df = df1_1.merge(df_grouped_1_, on='Host name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_lencode = merged_df[['Host name', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia a coluna 'Host name' para 'Host_name_le' in-place\n",
    "cluster_lencode.rename(columns={'Host name': 'Host_name_le'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatene df e cluster_lencode\n",
    "cluster_labelencode = pd.concat([df, cluster_lencode], axis=1)\n",
    "cluster_labelencode.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontre as colunas que contêm '_cos' ou '_sin' no nome\n",
    "cols_to_drop = cluster_labelencode.filter(regex='_cos|_sin').columns\n",
    "\n",
    "# Remova essas colunas\n",
    "cluster_labelencode = cluster_labelencode.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remova a coluna 'TimeDifference' in-place\n",
    "cluster_labelencode.drop(columns='TimeDifference', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labelencode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Encontre as colunas numéricas\n",
    "numeric_cols = cluster_labelencode.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Crie um boxplot para cada coluna numérica\n",
    "for col in numeric_cols:\n",
    "    fig = px.box(cluster_labelencode, x='Host name', y=col, color='cluster', title=f'Boxplot of {col} by Host name and cluster',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "    fig.update_layout(\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=600,\n",
    "        plot_bgcolor='rgba(0,0,0,0.02)'  # Fundo transparente\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labelencode.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Encontre as colunas numéricas\n",
    "numeric_cols = cluster_labelencode.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Encontre os clusters únicos\n",
    "unique_clusters = cluster_labelencode['cluster'].unique()\n",
    "\n",
    "# Crie um gráfico de barras para cada coluna numérica e cada cluster\n",
    "for cluster in unique_clusters:\n",
    "    for col in numeric_cols:\n",
    "        # Filtrar o dataframe para o cluster atual e calcular a média\n",
    "        df_filtered = cluster_labelencode[cluster_labelencode['cluster'] == cluster]\n",
    "        df_filtered = df_filtered.groupby('Host name')[col].mean().reset_index()\n",
    "        \n",
    "        fig = px.bar(df_filtered, x='Host name', y=col, title=f'Bar plot of average {col} by Host name and cluster {cluster}',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "        fig.update_layout(\n",
    "            xaxis={'categoryorder':'total descending'},\n",
    "            autosize=False,\n",
    "            width=800,\n",
    "            height=600,\n",
    "            plot_bgcolor='rgba(0,0,0,0.02)',  # Fundo quase transparente\n",
    "            showlegend=False  # Esconde a legenda\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Encontre as colunas numéricas\n",
    "numeric_cols = cluster_labelencode.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Encontre os clusters únicos\n",
    "unique_clusters = cluster_labelencode['cluster'].unique()\n",
    "\n",
    "# Crie um gráfico de barras para cada coluna numérica e cada cluster\n",
    "for cluster in unique_clusters:\n",
    "    for col in numeric_cols:\n",
    "        # Filtrar o dataframe para o cluster atual e calcular a média\n",
    "        df_filtered = cluster_labelencode[cluster_labelencode['cluster'] == cluster]\n",
    "        df_filtered = df_filtered.groupby(['Host name', 'year_month'])[col].mean().reset_index()\n",
    "        \n",
    "        fig = px.bar(df_filtered, x='Host name', y=col, color='year_month', title=f'Bar plot of average {col} by Host name, year_month and cluster {cluster}',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "        fig.update_layout(\n",
    "            xaxis={'categoryorder':'total descending'},\n",
    "            autosize=False,\n",
    "            width=800,\n",
    "            height=600,\n",
    "            plot_bgcolor='rgba(0,0,0,0.02)',  # Fundo quase transparente\n",
    "            showlegend=True  # Mostra a legenda\n",
    "        )\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfkit\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = pdfkit.configuration(wkhtmltopdf='C:\\\\Program Files\\\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')  # Use o caminho correto para o seu sistema\n",
    "pdfkit.from_file(html_file, pdf_file, configuration=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.offline as pyo\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Encontre as colunas numéricas\n",
    "numeric_cols = cluster_labelencode.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Get the path to your home directory\n",
    "home_dir = os.path.expanduser(\"~\")\n",
    "\n",
    "# Gráficos 1\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    # Create a path for the HTML file in your home directory\n",
    "    html_file = os.path.join(home_dir, f'graph1_{i}.html')\n",
    "\n",
    "    fig = px.box(cluster_labelencode, x='Host name', y=col, color='cluster', title=f'Boxplot of {col} by Host name and cluster',\n",
    "                 color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "    fig.update_layout(\n",
    "        xaxis={'categoryorder':'total descending'},\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=600,\n",
    "        plot_bgcolor='rgba(0,0,0,0.02)'  # Fundo transparente\n",
    "    )\n",
    "    pyo.plot(fig, filename=html_file, auto_open=False)\n",
    "\n",
    "# Gráficos 2\n",
    "unique_clusters = cluster_labelencode['cluster'].unique()\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    for j, col in enumerate(numeric_cols):\n",
    "        # Create a path for the HTML file in your home directory\n",
    "        html_file = os.path.join(home_dir, f'graph2_{i}_{j}.html')\n",
    "\n",
    "        df_filtered = cluster_labelencode[cluster_labelencode['cluster'] == cluster]\n",
    "        df_filtered = df_filtered.groupby('Host name')[col].mean().reset_index()\n",
    "        \n",
    "        fig = px.bar(df_filtered, x='Host name', y=col, title=f'Bar plot of average {col} by Host name and cluster {cluster}',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "        fig.update_layout(\n",
    "            xaxis={'categoryorder':'total descending'},\n",
    "            autosize=False,\n",
    "            width=800,\n",
    "            height=600,\n",
    "            plot_bgcolor='rgba(0,0,0,0.02)',  # Fundo quase transparente\n",
    "            showlegend=False  # Esconde a legenda\n",
    "        )\n",
    "        pyo.plot(fig, filename=html_file, auto_open=False)\n",
    "\n",
    "# Gráficos 3\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    for j, col in enumerate(numeric_cols):\n",
    "        # Create a path for the HTML file in your home directory\n",
    "        html_file = os.path.join(home_dir, f'graph3_{i}_{j}.html')\n",
    "\n",
    "        df_filtered = cluster_labelencode[cluster_labelencode['cluster'] == cluster]\n",
    "        df_filtered = df_filtered.groupby(['Host name', 'year_month'])[col].mean().reset_index()\n",
    "        \n",
    "        fig = px.bar(df_filtered, x='Host name', y=col, color='year_month', title=f'Bar plot of average {col} by Host name, year_month and cluster {cluster}',\n",
    "                     color_discrete_sequence=px.colors.qualitative.Pastel)  # Use a sequência de cores 'Pastel'\n",
    "        fig.update_layout(\n",
    "            xaxis={'categoryorder':'total descending'},\n",
    "            autosize=False,\n",
    "            width=800,\n",
    "            height=600,\n",
    "            plot_bgcolor='rgba(0,0,0,0.02)',  # Fundo quase transparente\n",
    "            showlegend=True  # Mostra a legenda\n",
    "        )\n",
    "        pyo.plot(fig, filename=html_file, auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
